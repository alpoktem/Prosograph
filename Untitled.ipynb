{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_proscript_as_dict(filename, delimiter=\"|\"):\n",
    "    #reads whole csv into one dict\n",
    "    proscript = defaultdict(list) # each value in each column is appended to a list\n",
    "\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f, delimiter=delimiter) # read rows into a dictionary format\n",
    "        for row in reader: # read a row as {column1: value1, column2: value2,...}\n",
    "            for (k,v) in row.items(): # go over each column name and value \n",
    "                if \"word\" in k or \"punctuation\" in k or \"pos\" in k:\n",
    "                    proscript[k].append(v) # append the value into the appropriate list\n",
    "                elif \"contour\" in k:\n",
    "                    print(k)\n",
    "                    print(v)\n",
    "                    arr_rep = json.loads(v)\n",
    "                    proscript[k].append(v)\n",
    "                else:\n",
    "                    try:\n",
    "                        proscript[k].append(float(v)) # real value\n",
    "                    except ValueError:\n",
    "                        print(\"ALARM:%s\"%v)\n",
    "                        proscript[k].append(0.0)\n",
    "    return proscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0_contour_xaxis\n",
      "[31.0, 38.0, 46.0, 53.0, 61.0, 68.0, 76.0, 83.0]\n",
      "f0_contour\n",
      "[118.732, 118.813, 113.822, 112.432, 112.617, 112.802, 112.425, 111.788]\n",
      "i0_contour_xaxis\n",
      "[]\n",
      "i0_contour\n",
      "[]\n",
      "f0_contour_xaxis\n",
      "[29.0, 31.0, 34.0, 36.0, 39.0, 41.0, 43.0, 46.0, 48.0, 51.0, 53.0, 56.0, 58.0, 60.0, 63.0, 65.0, 68.0, 70.0, 72.0, 75.0, 77.0, 80.0, 82.0]\n",
      "f0_contour\n",
      "[126.499, 124.192, 124.85, 123.993, 122.917, 121.252, 120.747, 121.787, 123.004, 124.813, 126.054, 129.036, 131.427, 133.221, 134.845, 137.759, 138.959, 140.582, 142.083, 144.036, 143.609, 143.57, 141.698]\n",
      "i0_contour_xaxis\n",
      "[]\n",
      "i0_contour\n",
      "[]\n",
      "f0_contour_xaxis\n",
      "[8.0, 12.0, 16.0, 20.0, 25.0, 29.0, 33.0, 37.0, 41.0, 45.0, 50.0, 54.0, 58.0]\n",
      "f0_contour\n",
      "[140.313, 141.139, 139.681, 139.739, 130.649, 129.954, 128.96, 127.306, 125.999, 125.66, 126.181, 127.794, 127.581]\n",
      "i0_contour_xaxis\n",
      "[]\n",
      "i0_contour\n",
      "[]\n",
      "f0_contour_xaxis\n",
      "[7.0, 10.0, 14.0, 17.0, 20.0, 23.0, 27.0, 30.0, 33.0, 36.0, 40.0, 43.0, 46.0]\n",
      "f0_contour\n",
      "[103.365, 102.48, 101.025, 99.161, 96.645, 94.293, 89.439, 88.651, 84.38, 83.52, 83.383, 83.419, 83.28]\n",
      "i0_contour_xaxis\n",
      "[]\n",
      "i0_contour\n",
      "[]\n",
      "f0_contour_xaxis\n",
      "[]\n",
      "f0_contour\n",
      "[]\n",
      "i0_contour_xaxis\n",
      "[]\n",
      "i0_contour\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "prodict = read_proscript_as_dict('newdata/alp_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arrstr = \"[31.0, 38.0, 46.0, 53.0, 61.0, 68.0, 76.0, 83.0]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31.0, 38.0, 46.0, 53.0, 61.0, 68.0, 76.0, 83.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(arrstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['word', 'start_time', 'end_time', 'duration', 'pause_before', 'pause_after', 'pos', 'punctuation_before', 'punctuation_after', 'speech_rate_phon', 'f0_mean', 'i0_mean', 'f0_slope', 'i0_slope', 'f0_sd', 'i0_sd', 'f0_range', 'i0_range', 'f0_contour_xaxis', 'f0_contour', 'i0_contour_xaxis', 'i0_contour'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[31.0, 38.0, 46.0, 53.0, 61.0, 68.0, 76.0, 83.0]',\n",
       " '[29.0, 31.0, 34.0, 36.0, 39.0, 41.0, 43.0, 46.0, 48.0, 51.0, 53.0, 56.0, 58.0, 60.0, 63.0, 65.0, 68.0, 70.0, 72.0, 75.0, 77.0, 80.0, 82.0]',\n",
       " '[8.0, 12.0, 16.0, 20.0, 25.0, 29.0, 33.0, 37.0, 41.0, 45.0, 50.0, 54.0, 58.0]',\n",
       " '[7.0, 10.0, 14.0, 17.0, 20.0, 23.0, 27.0, 30.0, 33.0, 36.0, 40.0, 43.0, 46.0]',\n",
       " '[]']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodict['f0_contour_xaxis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
